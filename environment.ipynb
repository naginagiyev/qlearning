{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de3db45",
   "metadata": {},
   "source": [
    "GRID WALK ENVIRONMENT : A REINFORCEMENT LEARNING PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb402ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipython in c:\\programdata\\anaconda3\\lib\\site-packages (8.10.0)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (4.4.2)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (0.18.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (2.17.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (5.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython) (3.0.43)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython) (0.2.5)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython) (0.8.3)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from asttokens->stack-data->ipython) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# download numpy and ipython (is used to clear terminal to show prints as animation)\n",
    "!pip install numpy\n",
    "!pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f609a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | # | # |   |   |   |   |   | # |   |   |   \n",
      "  |   |   |   |   |   |   |   | # |   |   | # \n",
      "# |   |   |   |   |   |   |   |   |   |   |   \n",
      "  |   |   | # |   |   |   |   |   |   |   | # \n",
      "  | # |   |   |   |   |   |   |   |   |   |   \n",
      "  |   |   |   |   |   |   |   |   | # | # | # \n",
      "  |   | # |   |   | # |   |   | # |   |   |   \n",
      "  |   |   |   |   |   |   | # |   | # |   |   \n",
      "  |   |   | # |   |   |   |   |   |   |   |   \n",
      "  |   |   |   |   | # |   |   |   |   |   |   \n",
      "# | # |   |   | # | # |   |   |   |   |   |   \n",
      "  |   | # |   |   |   | # |   | # |   |   | â–  \n",
      "Congratulations! You reached the goal!\n",
      "Episode 750 finished\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries (everything will be from scratch)\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class BombAvoider:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.SIZE = 12 # size of the grid (in this case it is 12x12) \n",
    "        self.NUMS_OF_BOMBS = 30 # the number of the bombs in the grid\n",
    "        \n",
    "        # coordinates of the player that it should start at first\n",
    "        self.row = 1 \n",
    "        self.col = 1\n",
    "        \n",
    "        # generate the coordinates where bombs should located\n",
    "        self.bomb_coordinates = [(random.randint(1, self.SIZE), random.randint(1, self.SIZE)) for _ in range(self.NUMS_OF_BOMBS)]\n",
    "        self.bomb_coordinates = [coordinate for coordinate in self.bomb_coordinates if coordinate not in [(1, 1), (self.SIZE, self.SIZE)]]\n",
    "        \n",
    "        # dictionary to keep Q-values\n",
    "        self.q_values = {}\n",
    "        \n",
    "        # This code generates random Q-values in each state for each action. Then these Q-Values will be updated.\n",
    "        # In each state, there is 4 actions: up, down, left and right. Each action has its own Q-Value.\n",
    "        # Whichever move has the highest Q-Value is the next best move for that coordinate.\n",
    "        for row in range(1, self.SIZE + 1):\n",
    "            for col in range(1, self.SIZE + 1):\n",
    "                state = (row, col)\n",
    "                self.q_values[state] = {(-1, 0): np.random.rand(), # up\n",
    "                                        (1, 0): np.random.rand(), # down \n",
    "                                        (0, -1): np.random.rand(), # left \n",
    "                                        (0, 1): np.random.rand()} # right \n",
    "        \n",
    "        # epilson number which shows how much percent of our agent is tend to explore new things\n",
    "        self.epsilon = 0.1\n",
    "        \n",
    "    # draw our grid world with its agent and bombs    \n",
    "    def draw_grid(self):\n",
    "        for i in range(self.SIZE):\n",
    "            for j in range(self.SIZE):\n",
    "                if (i + 1, j + 1) == (self.row, self.col):\n",
    "                    print(\"\\u25A0\", end=\" \")\n",
    "                elif (i + 1, j + 1) in self.bomb_coordinates:\n",
    "                    print(\"#\", end=\" \")\n",
    "                else:\n",
    "                    print(\" \", end=\" \")\n",
    "                if j < self.SIZE - 1:\n",
    "                    print(\"|\", end=\" \")\n",
    "            print()\n",
    "            \n",
    "    # returns the current coordinates of the agent\n",
    "    def get_current_coordinates(self):\n",
    "        return self.row, self.col\n",
    "    \n",
    "    # used for find next state using our current state and taken action\n",
    "    # in other words, it takes current state, action as inputs and returns the agents next state (coordinates)\n",
    "    def state_after_action(self, current_state, action):\n",
    "        if current_state is not None and action is not None:\n",
    "            return tuple(x + y for x, y in zip(current_state, action))\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # this part of code select agent's action.\n",
    "    # in this case, this action is 10% random action (because epilson is 0.1)\n",
    "    # and 90% is the best action best for the state based on Q-Values\n",
    "    def select_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(list(self.q_values[state].keys()))\n",
    "        else:\n",
    "            return max(self.q_values[state].items(), key = lambda x: x[1])[0]\n",
    "        \n",
    "    # check if our action is valid, if yes set current location to new coordinates \n",
    "    def take_action(self, action):\n",
    "        if action is not None:\n",
    "            next_state = self.state_after_action(self.get_current_coordinates(), action)\n",
    "            row, col = next_state\n",
    "            \n",
    "            # check if the next state is between the boundaries, if yes set current location to new coordinates \n",
    "            if 1 <= row <= self.SIZE and 1 <= col <= self.SIZE:\n",
    "                self.row = row\n",
    "                self.col = col\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    # reward system \n",
    "    def get_reward(self, current_state, next_state):\n",
    "        # if agent hits the bomb, it gets negative reward (called penalty). \n",
    "        # it makes agent to avoid bombs \n",
    "        if next_state in self.bomb_coordinates:\n",
    "            return -1\n",
    "        # if agent gets the finish, it gets a positive reward\n",
    "        elif next_state == (self.SIZE, self.SIZE):\n",
    "            return 1  \n",
    "        # in other cases, agent does not get anything \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # update q_value\n",
    "    def update_q_values(self, current_state, action, reward, next_state):\n",
    "        q_sa = self.q_values[current_state][action]\n",
    "        self.q_values[current_state][action] = q_sa + 0.1 * (reward + 0.9 * max(self.q_values[next_state].values()) - q_sa)\n",
    "        return True\n",
    "\n",
    "# create an object from the Bomb Avoider class\n",
    "environment = BombAvoider()\n",
    "# the number of episodes \n",
    "episodes = 750\n",
    "\n",
    "# 1 episode is until when agent hit the bomb or get the finish \n",
    "for episode in range(episodes):\n",
    "    # send agent to start point (1, 1) after an episode ends \n",
    "    environment.row, environment.col = 1, 1\n",
    "        \n",
    "    # \"while true\" loop to take an action until hit a bomb or get the finish\n",
    "    while True:\n",
    "        # this function clear output before print new thing, so you see the agent's moving as animation\n",
    "        clear_output(wait=True)\n",
    "        # get current state \n",
    "        current_state = environment.get_current_coordinates()\n",
    "        # select an action \n",
    "        action = environment.select_action(current_state)\n",
    "        # if action is valid take that action\n",
    "        environment.take_action(action)\n",
    "        # draw grid after perform an action\n",
    "        environment.draw_grid()\n",
    "        # get next state \n",
    "        next_state = environment.get_current_coordinates()\n",
    "        # get reward for selected action\n",
    "        reward = environment.get_reward(current_state, next_state)\n",
    "        # update Q-Values\n",
    "        environment.update_q_values(current_state, action, reward, next_state)\n",
    "        \n",
    "        # make last 10 episodes slower to see agent's progress better\n",
    "        if episode >= episodes - 10:\n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        # break loop if agent hit a bomb\n",
    "        if environment.get_current_coordinates() in environment.bomb_coordinates:\n",
    "            print(\"You hit the bomb! Game over!\")\n",
    "            break\n",
    "        \n",
    "        # break loop if agent get the finish\n",
    "        if environment.get_current_coordinates() == (environment.SIZE, environment.SIZE):\n",
    "            print(\"Congratulations! You reached the goal!\")\n",
    "            break\n",
    "    # print which episode it is\n",
    "    print(f\"Episode {episode + 1} finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
